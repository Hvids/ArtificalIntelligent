{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hvidsmen/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/hvidsmen/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/hvidsmen/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/hvidsmen/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-758d29429358>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/hvidsmen/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/hvidsmen/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hvidsmen/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hvidsmen/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hvidsmen/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "latent_space = 128\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.46477460861206055\n",
      "score = 0.284026563167572\n",
      "score = 0.27533456683158875\n",
      "score = 0.2624067962169647\n",
      "score = 0.25136396288871765\n",
      "score = 0.2444850206375122\n",
      "score = 0.24982768297195435\n",
      "score = 0.2501866817474365\n",
      "score = 0.25556135177612305\n",
      "score = 0.25790929794311523\n",
      "score = 0.25386902689933777\n"
     ]
    }
   ],
   "source": [
    "ae_weights = {\n",
    "    'encoder_w': tf.Variable(tf.truncated_normal([784,latent_space],stddev=0.1)),\n",
    "    'encoder_b': tf.Variable(tf.truncated_normal([latent_space],stddev=0.1)),\n",
    "    'decoder_w':tf.Variable(tf.truncated_normal([latent_space,784],stddev=0.1)),\n",
    "    'decoder_b':tf.Variable(tf.truncated_normal([784],stddev=0.1)),\n",
    "}\n",
    "ae_input = tf.placeholder(tf.float32,[batch_size,784])\n",
    "hidden = tf.nn.sigmoid(tf.matmul(ae_input,ae_weights['encoder_w']) + ae_weights['encoder_b'])\n",
    "\n",
    "visible_logits = tf.matmul(hidden, ae_weights['decoder_w']) + ae_weights['decoder_b']\n",
    "visible = tf.nn.sigmoid(visible_logits)\n",
    "\n",
    "\n",
    "\n",
    "ae_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=visible_logits,labels=ae_input))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "ae_op = optimizer.minimize(ae_cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "        sess.run(ae_op,feed_dict={ae_input:x_batch})\n",
    "        score = sess.run(ae_cost,feed_dict={ae_input:x_batch})\n",
    "        if i%10==0:\n",
    "            print(f'score = {score}')\n",
    "    print(f'score = {score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разряженный автоинкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.6553716659545898\n",
      "score = 0.40043017268180847\n",
      "score = 0.36065372824668884\n",
      "score = 0.2787542939186096\n",
      "score = 0.2691074013710022\n",
      "score = 0.2762235403060913\n",
      "score = 0.2645537853240967\n",
      "score = 0.26074400544166565\n",
      "score = 0.24193768203258514\n",
      "score = 0.25175613164901733\n",
      "score = 0.23993618786334991\n"
     ]
    }
   ],
   "source": [
    "rho=0.05\n",
    "beta = 1.0\n",
    "\n",
    "ae_weights = {\n",
    "    'encoder_w': tf.Variable(tf.truncated_normal([784,latent_space],stddev=0.1)),\n",
    "    'encoder_b': tf.Variable(tf.truncated_normal([latent_space],stddev=0.1)),\n",
    "    'decoder_w':tf.Variable(tf.truncated_normal([latent_space,784],stddev=0.1)),\n",
    "    'decoder_b':tf.Variable(tf.truncated_normal([784],stddev=0.1)),\n",
    "}\n",
    "ae_input = tf.placeholder(tf.float32,[batch_size,784])\n",
    "hidden = tf.nn.sigmoid(tf.matmul(ae_input,ae_weights['encoder_w']) + ae_weights['encoder_b'])\n",
    "\n",
    "noise_hidden = tf.nn.relu(hidden-0.1) + 0.1\n",
    "noise_visible = tf.nn.sigmoid(\n",
    "    tf.matmul(noise_hidden, ae_weights['decoder_w']) + ae_weights['decoder_b']\n",
    ")\n",
    "\n",
    "deta_rho = tf.reduce_mean(hidden,0)\n",
    "reg_cost= -tf.reduce_mean(tf.log(deta_rho/rho)*rho + tf.log(1-deta_rho/(1-rho)*(1-rho)))\n",
    "visible_logits = tf.matmul(hidden, ae_weights['decoder_w']) + ae_weights['decoder_b']\n",
    "visible = tf.nn.sigmoid(visible_logits)\n",
    "\n",
    "\n",
    "\n",
    "ae_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=visible_logits,labels=ae_input))\n",
    "total_cost = reg_cost + ae_cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "ae_op = optimizer.minimize(total_cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "        sess.run(ae_op,feed_dict={ae_input:x_batch})\n",
    "        score = sess.run(ae_cost,feed_dict={ae_input:x_batch})\n",
    "        if i%10==0:\n",
    "            print(f'score = {score}')\n",
    "    print(f'score = {score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шумоподовляющий автокодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.6425566673278809\n",
      "score = 0.4087451100349426\n",
      "score = 0.3643653392791748\n",
      "score = 0.28148552775382996\n",
      "score = 0.273108571767807\n",
      "score = 0.25276264548301697\n",
      "score = 0.2478683441877365\n",
      "score = 0.25839704275131226\n",
      "score = 0.26120415329933167\n",
      "score = 0.24736253917217255\n",
      "score = 0.23616082966327667\n"
     ]
    }
   ],
   "source": [
    "rho=0.05\n",
    "beta = 1.0\n",
    "\n",
    "ae_weights = {\n",
    "    'encoder_w': tf.Variable(tf.truncated_normal([784,latent_space],stddev=0.1)),\n",
    "    'encoder_b': tf.Variable(tf.truncated_normal([latent_space],stddev=0.1)),\n",
    "    'decoder_w':tf.Variable(tf.truncated_normal([latent_space,784],stddev=0.1)),\n",
    "    'decoder_b':tf.Variable(tf.truncated_normal([784],stddev=0.1)),\n",
    "}\n",
    "ae_input = tf.placeholder(tf.float32,[batch_size,784])\n",
    "noise_input = tf.placeholder(tf.float32,[batch_size,784])\n",
    "\n",
    "hidden = tf.nn.sigmoid(tf.matmul(noise_input,ae_weights['encoder_w']) + ae_weights['encoder_b'])\n",
    "\n",
    "noise_hidden = tf.nn.relu(hidden-0.1) + 0.1\n",
    "noise_visible = tf.nn.sigmoid(\n",
    "    tf.matmul(noise_hidden, ae_weights['decoder_w']) + ae_weights['decoder_b']\n",
    ")\n",
    "\n",
    "deta_rho = tf.reduce_mean(hidden,0)\n",
    "reg_cost= -tf.reduce_mean(tf.log(deta_rho/rho)*rho + tf.log(1-deta_rho/(1-rho)*(1-rho)))\n",
    "visible_logits = tf.matmul(hidden, ae_weights['decoder_w']) + ae_weights['decoder_b']\n",
    "visible = tf.nn.sigmoid(visible_logits)\n",
    "\n",
    "\n",
    "\n",
    "ae_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=visible_logits,labels=ae_input))\n",
    "total_cost = reg_cost + ae_cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "ae_op = optimizer.minimize(total_cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "        noise_mask = np.random.uniform(0.,1.,[batch_size,784]) < 0.3\n",
    "        noise_batch = x_batch.copy()\n",
    "        noise_batch[noise_mask] = 0.0\n",
    "        sess.run(ae_op,feed_dict={ae_input:x_batch,noise_input:noise_batch})\n",
    "        score = sess.run(ae_cost,feed_dict={ae_input:x_batch,noise_input:noise_batch})\n",
    "        if i%10==0:\n",
    "            print(f'score = {score}')\n",
    "    print(f'score = {score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверточный автоинкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5757030844688416\n",
      "score = 0.3697914481163025\n",
      "score = 0.27113988995552063\n",
      "score = 0.2394971400499344\n",
      "score = 0.21175484359264374\n",
      "score = 0.21590088307857513\n",
      "score = 0.18427354097366333\n",
      "score = 0.19019383192062378\n",
      "score = 0.1854918748140335\n",
      "score = 0.1724018156528473\n",
      "score = 0.16910801827907562\n"
     ]
    }
   ],
   "source": [
    "batch_size, learning_rate = 64,0.01\n",
    "\n",
    "ae_weights = {\n",
    "    \"conv\": tf.Variable(tf.truncated_normal([5,5,1,4],stddev=0.1)),\n",
    "    'b_hidden':tf.Variable(tf.truncated_normal([4],stddev=0.1)),\n",
    "    'deconv':tf.Variable(tf.truncated_normal([5,5,1,4],stddev=0.1)),\n",
    "    'b_visible':tf.Variable(tf.truncated_normal([1],stddev=0.1))\n",
    "    \n",
    "}\n",
    "input_shape = tf.stack([batch_size,28,28,1])\n",
    "ae_input = tf.placeholder(tf.float32,[batch_size,784])\n",
    "images = tf.reshape(ae_input,[-1,28,28,1])\n",
    "hidden_logits = tf.nn.conv2d(images, ae_weights['conv'],strides=[1,2,2,1],padding='SAME') + ae_weights['b_hidden']\n",
    "\n",
    "hidden = tf.nn.sigmoid(hidden_logits)\n",
    "visible_logits = tf.nn.conv2d_transpose(hidden,\n",
    "                                        ae_weights['deconv'],\n",
    "                                        input_shape, strides=[1,2,2,1],\n",
    "                                        padding='SAME'\n",
    "                                       ) + ae_weights['b_visible']\n",
    "\n",
    "visible = tf.nn.sigmoid(visible_logits)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "conv_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=visible_logits,labels=images))\n",
    "conv_op = optimizer.minimize(conv_cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "        sess.run(conv_op,feed_dict={ae_input:x_batch})\n",
    "        score = sess.run(conv_cost,feed_dict={ae_input:x_batch})\n",
    "        if i%10==0:\n",
    "            print(f'score = {score}')\n",
    "    print(f'score = {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
